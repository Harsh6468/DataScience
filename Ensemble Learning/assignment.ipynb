{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7ce49b",
   "metadata": {},
   "source": [
    "## **Ensemble Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8fe06",
   "metadata": {},
   "source": [
    "### **Theoretical**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df54b8",
   "metadata": {},
   "source": [
    "### **1. Can we use Bagging for regression problems?**\n",
    "Yes, Bagging can be used for regression problems. Bagging (Bootstrap Aggregating) is a general-purpose ensemble method that can be applied to both classification and regression. In the regression context, it involves training multiple regressors (e.g., Decision Trees) on different bootstrapped subsets of the training data. The final prediction is obtained by averaging the outputs of all base regressors. This method helps in reducing variance, leading to more robust and stable predictions without significantly increasing bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd9067",
   "metadata": {},
   "source": [
    "### **2. What is the difference between multiple model training and single model training?**\n",
    "Single model training involves creating one predictive model from the entire dataset. While this can be simple and efficient, the model may underfit or overfit depending on its complexity.\n",
    "\n",
    "Multiple model training refers to training several models either independently (like in Bagging) or sequentially (like in Boosting). These models are then combined to make a final prediction. This often results in better generalization, reduced overfitting, and higher accuracy due to the aggregation of diverse model perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1acb2d",
   "metadata": {},
   "source": [
    "### **3. Explain the concept of feature randomness in Random Forest?**\n",
    "Random Forest introduces feature randomness by selecting a random subset of features at each split when building a tree. This process is called \"feature bagging.\" Instead of using the best split among all features, it chooses the best among a random subset. This ensures the individual trees in the forest are diverse and less correlated, improving overall model performance and generalization while reducing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc2704",
   "metadata": {},
   "source": [
    "### **4. What is OOB (Out-of-Bag) Score?**\n",
    "The Out-of-Bag (OOB) Score is an internal validation method used in ensemble techniques like Bagging and Random Forest. Each base model is trained on a bootstrap sample, leaving out approximately one-third of the data. These left-out samples (OOB samples) are used to test the model’s performance. The OOB score gives an unbiased estimate of model accuracy without requiring a separate validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939fd43a",
   "metadata": {},
   "source": [
    "### **5. How can you measure the importance of features in a Random Forest model?**\n",
    "Random Forest models measure feature importance in two common ways:\n",
    "1. Mean Decrease in Impurity (Gini Importance): Measures how much each feature contributes to decreasing the impurity across all trees.\n",
    "2. Permutation Importance: Randomly shuffles each feature and observes the increase in model error. A significant increase indicates a more important feature.\n",
    "\n",
    "These methods help understand which features are most influential in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb614bf",
   "metadata": {},
   "source": [
    "### **6. Explain the working principle of a Bagging Classifier.**\n",
    "A Bagging Classifier builds multiple models (e.g., decision trees) on different bootstrapped subsets of the training data. Each model is trained independently. During prediction, the outputs of these models are combined using a majority vote (for classification) or average (for regression). This reduces variance and improves the model’s generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181a0c3",
   "metadata": {},
   "source": [
    "### **7. How do you evaluate a Bagging Classifier’s performance?**\n",
    "You can evaluate a Bagging Classifier using various classification metrics, such as:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- ROC-AUC Score\n",
    "\n",
    "Additionally, Out-of-Bag (OOB) error estimation can be used for validation without needing a separate test set. Cross-validation is also a common method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1cea8",
   "metadata": {},
   "source": [
    "### **8. How does a Bagging Regressor work?**\n",
    "A Bagging Regressor works by training multiple regression models (e.g., decision trees) on bootstrapped datasets. Each model makes a prediction, and the final output is the average of all these predictions. This helps to reduce the model variance and leads to more stable and accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772a192",
   "metadata": {},
   "source": [
    "### **9. What is the main advantage of ensemble techniques?**\n",
    "The main advantage is improved prediction accuracy through the combination of multiple models. Ensemble methods reduce overfitting (variance), underfitting (bias), and improve generalization by leveraging the collective knowledge of several models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8644cf2",
   "metadata": {},
   "source": [
    "### **10. What is the main challenge of ensemble methods?**\n",
    "The biggest challenges include:\n",
    "- Increased computational cost and training time.\n",
    "- Reduced interpretability.\n",
    "- Complexity in model tuning.\n",
    "- Risk of overfitting if not properly validated (especially in Boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053304e",
   "metadata": {},
   "source": [
    "### **11. Explain the key idea behind ensemble techniques.**\n",
    "The core idea is to combine multiple weak learners (models that individually perform slightly better than random guessing) to form a strong learner. By aggregating diverse models—each capturing different patterns or errors—the ensemble typically performs better than any individual model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741d312",
   "metadata": {},
   "source": [
    "### **12. What is a Random Forest Classifier?**\n",
    "A Random Forest Classifier is an ensemble learning method that constructs multiple decision trees using bagged subsets of data and feature subsets. Each tree votes for a class, and the final prediction is based on majority voting. It’s known for being accurate, robust, and resistant to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d0693",
   "metadata": {},
   "source": [
    "### **13. What are the main types of ensemble techniques?**\n",
    "The main types are:\n",
    "- Bagging (e.g., Random Forest)\n",
    "- Boosting (e.g., AdaBoost, Gradient Boosting, XGBoost)\n",
    "- Stacking (combining heterogeneous models)\n",
    "- Voting (hard/soft voting from different models)\n",
    "- Blending (a simplified version of stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f134e",
   "metadata": {},
   "source": [
    "### **14. What is ensemble learning in machine learning?**\n",
    "Ensemble learning involves combining multiple models to improve overall performance. Instead of relying on a single model, ensembles use the strengths of multiple models to produce more accurate, stable, and robust predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356c6d6",
   "metadata": {},
   "source": [
    "### **15. When should we avoid using ensemble methods?**\n",
    "Avoid ensemble methods when:\n",
    "- The dataset is very small.\n",
    "- Model explainability is critical.\n",
    "- There are strict latency or computational constraints.\n",
    "- The performance gain is marginal compared to added complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b26874",
   "metadata": {},
   "source": [
    "### **16. How does Bagging help in reducing overfitting?**\n",
    "Bagging reduces overfitting by introducing variance among base learners through bootstrap sampling. Averaging multiple predictions reduces the variance of the final model, making it more stable and less likely to overfit to the noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ef532",
   "metadata": {},
   "source": [
    "### **17. Why is Random Forest better than a single Decision Tree?**\n",
    "Random Forest is better because:\n",
    "- It reduces overfitting by averaging many uncorrelated trees.\n",
    "- It improves accuracy and robustness.\n",
    "- It handles noise and outliers better.\n",
    "- It provides better generalization to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa7a97",
   "metadata": {},
   "source": [
    "### **18. What is the role of bootstrap sampling in Bagging?**\n",
    "Bootstrap sampling involves sampling data points with replacement to form new training sets. This ensures each base model gets a different subset, increasing model diversity. When their outputs are aggregated, the ensemble benefits from reduced variance and better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01bf91",
   "metadata": {},
   "source": [
    "### **19. What are some real-world applications of ensemble techniques?**\n",
    "- Finance: Credit scoring, stock prediction.\n",
    "- Healthcare: Disease diagnosis, risk prediction.\n",
    "- E-commerce: Recommendation systems, fraud detection.\n",
    "- Image Recognition: Object detection, facial recognition.\n",
    "- Natural Language Processing: Sentiment analysis, spam detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01888f",
   "metadata": {},
   "source": [
    "### **20. What is the difference between Bagging and Boosting?**\n",
    "| Feature     | Bagging                    | Boosting                        |\n",
    "| ----------- | -------------------------- | ------------------------------- |\n",
    "| Training    | Parallel                   | Sequential                      |\n",
    "| Goal        | Reduce variance            | Reduce bias                     |\n",
    "| Model Focus | Equal weight on all models | Later models fix earlier errors |\n",
    "| Example     | Random Forest              | AdaBoost, XGBoost               |\n",
    "| Risk        | Less prone to overfitting  | More prone to overfitting       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae2c1d",
   "metadata": {},
   "source": [
    "### **Practical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7eae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "# 21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07fd8cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE: 5021.000687070409\n"
     ]
    }
   ],
   "source": [
    "# 22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=0.3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=50, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Bagging Regressor MSE:\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c3abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius: 0.0581\n",
      "mean texture: 0.0154\n",
      "mean perimeter: 0.0736\n",
      "mean area: 0.0476\n",
      "mean smoothness: 0.0055\n",
      "mean compactness: 0.0056\n",
      "mean concavity: 0.0682\n",
      "mean concave points: 0.0818\n",
      "mean symmetry: 0.0028\n",
      "mean fractal dimension: 0.0028\n",
      "radius error: 0.0230\n",
      "texture error: 0.0032\n",
      "perimeter error: 0.0063\n",
      "area error: 0.0317\n",
      "smoothness error: 0.0037\n",
      "compactness error: 0.0033\n",
      "concavity error: 0.0033\n",
      "concave points error: 0.0057\n",
      "symmetry error: 0.0038\n",
      "fractal dimension error: 0.0043\n",
      "worst radius: 0.0895\n",
      "worst texture: 0.0192\n",
      "worst perimeter: 0.1411\n",
      "worst area: 0.1152\n",
      "worst smoothness: 0.0086\n",
      "worst compactness: 0.0142\n",
      "worst concavity: 0.0200\n",
      "worst concave points: 0.1252\n",
      "worst symmetry: 0.0101\n",
      "worst fractal dimension: 0.0068\n"
     ]
    }
   ],
   "source": [
    "# 23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=1)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "for feature, importance in zip(data.feature_names, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773fc7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor MSE: 0.04202982456140351\n",
      "Decision Tree Regressor MSE: 0.07017543859649122\n"
     ]
    }
   ],
   "source": [
    "# 24. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "dt = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Regressor MSE:\", mean_squared_error(y_test, rf_pred))\n",
    "print(\"Decision Tree Regressor MSE:\", mean_squared_error(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1dce8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest OOB Score: 0.949748743718593\n"
     ]
    }
   ],
   "source": [
    "# 25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
    "rf_oob = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=1)\n",
    "rf_oob.fit(X_train, y_train)\n",
    "print(\"Random Forest OOB Score:\", rf_oob.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074fd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier (SVM) Accuracy: 0.9005847953216374\n"
     ]
    }
   ],
   "source": [
    "# 26. Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_bag = BaggingClassifier(estimator=SVC(probability=True), n_estimators=10, random_state=1)\n",
    "svm_bag.fit(X_train, y_train)\n",
    "y_pred = svm_bag.predict(X_test)\n",
    "print(\"Bagging Classifier (SVM) Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08fdce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (10 trees): Accuracy = 0.9357\n",
      "Random Forest (50 trees): Accuracy = 0.9415\n",
      "Random Forest (100 trees): Accuracy = 0.9474\n",
      "Random Forest (200 trees): Accuracy = 0.9532\n"
     ]
    }
   ],
   "source": [
    "# 27. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
    "for n in [10, 50, 100, 200]:\n",
    "    clf = RandomForestClassifier(n_estimators=n, random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Random Forest ({n} trees): Accuracy = {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34b838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier (Logistic Regression) AUC Score: 0.9902998236331569\n"
     ]
    }
   ],
   "source": [
    "# 28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "log_bag = BaggingClassifier(estimator=LogisticRegression(max_iter=1000), n_estimators=10, random_state=1)\n",
    "log_bag.fit(X_train, y_train)\n",
    "probs = log_bag.predict_proba(X_test)[:, 1]\n",
    "print(\"Bagging Classifier (Logistic Regression) AUC Score:\", roc_auc_score(y_test, probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0c7cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: Importance = 0.0011\n",
      "Feature 1: Importance = 0.0136\n",
      "Feature 2: Importance = 0.0014\n",
      "Feature 3: Importance = 0.0013\n",
      "Feature 4: Importance = 0.0035\n",
      "Feature 5: Importance = 0.0023\n",
      "Feature 6: Importance = 0.0096\n",
      "Feature 7: Importance = 0.0470\n",
      "Feature 8: Importance = 0.0019\n",
      "Feature 9: Importance = 0.0019\n",
      "Feature 10: Importance = 0.0038\n",
      "Feature 11: Importance = 0.0018\n",
      "Feature 12: Importance = 0.0021\n",
      "Feature 13: Importance = 0.0071\n",
      "Feature 14: Importance = 0.0014\n",
      "Feature 15: Importance = 0.0026\n",
      "Feature 16: Importance = 0.0040\n",
      "Feature 17: Importance = 0.0026\n",
      "Feature 18: Importance = 0.0023\n",
      "Feature 19: Importance = 0.0025\n",
      "Feature 20: Importance = 0.0270\n",
      "Feature 21: Importance = 0.0410\n",
      "Feature 22: Importance = 0.5588\n",
      "Feature 23: Importance = 0.0347\n",
      "Feature 24: Importance = 0.0080\n",
      "Feature 25: Importance = 0.0077\n",
      "Feature 26: Importance = 0.0100\n",
      "Feature 27: Importance = 0.1900\n",
      "Feature 28: Importance = 0.0039\n",
      "Feature 29: Importance = 0.0053\n"
     ]
    }
   ],
   "source": [
    "# 29. Train a Random Forest Regressor and analyze feature importance scores.\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "for i, imp in enumerate(importances):\n",
    "    print(f\"Feature {i}: Importance = {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa38d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.9532163742690059\n",
      "Random Forest Classifier Accuracy: 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# 30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
    "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=1)\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "bag_acc = accuracy_score(y_test, bag.predict(X_test))\n",
    "rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "print(\"Bagging Classifier Accuracy:\", bag_acc)\n",
    "print(\"Random Forest Classifier Accuracy:\", rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f17416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Accuracy: 0.9028571428571428\n"
     ]
    }
   ],
   "source": [
    "# 31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=1), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f910c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor (10 estimators): MSE = 0.0901\n",
      "Bagging Regressor (50 estimators): MSE = 0.0835\n",
      "Bagging Regressor (100 estimators): MSE = 0.0820\n"
     ]
    }
   ],
   "source": [
    "# 32. Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
    "for n in [10, 50, 100]:\n",
    "    model = BaggingRegressor(n_estimators=n, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    print(f\"Bagging Regressor ({n} estimators): MSE = {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "514d6192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 25\n"
     ]
    }
   ],
   "source": [
    "# 33. Train a Random Forest Classifier and analyze misclassified samples.\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "misclassified = X_test[y_pred != y_test]\n",
    "print(\"Number of misclassified samples:\", len(misclassified))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80403ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.83\n",
      "Bagging Classifier Accuracy: 0.9033333333333333\n"
     ]
    }
   ],
   "source": [
    "# 34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
    "tree = DecisionTreeClassifier(random_state=1)\n",
    "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=1)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, tree.predict(X_test)))\n",
    "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, bag.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33056aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2d8ec66bcb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 35. Train a Random Forest Classifier and visualize the confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "475fa0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.9433333333333334\n"
     ]
    }
   ],
   "source": [
    "# 36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('tree', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stack.fit(X_train, y_train)\n",
    "print(\"Stacking Classifier Accuracy:\", stack.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97fcb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Important Features:\n",
      "Feature 1 Importance: 0.1532\n",
      "Feature 0 Importance: 0.1415\n",
      "Feature 17 Importance: 0.1111\n",
      "Feature 12 Importance: 0.0624\n",
      "Feature 19 Importance: 0.0622\n"
     ]
    }
   ],
   "source": [
    "# 37. Train a Random Forest Classifier and print the top 5 most important features.\n",
    "import numpy as np\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "top_indices = np.argsort(importances)[-5:][::-1]\n",
    "print(\"Top 5 Important Features:\")\n",
    "for idx in top_indices:\n",
    "    print(f\"Feature {idx} Importance: {importances[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946e8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8807947019867549\n",
      "Recall: 0.9236111111111112\n",
      "F1-Score: 0.9016949152542373\n"
     ]
    }
   ],
   "source": [
    "# 38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "bag = BaggingClassifier(n_estimators=50, random_state=1)\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e359884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth = None, Accuracy = 0.9167\n",
      "Max Depth = 5, Accuracy = 0.8967\n",
      "Max Depth = 10, Accuracy = 0.9133\n",
      "Max Depth = 15, Accuracy = 0.9167\n"
     ]
    }
   ],
   "source": [
    "# 39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
    "for depth in [None, 5, 10, 15]:\n",
    "    model = RandomForestClassifier(max_depth=depth, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"Max Depth = {depth}, Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a23f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Estimator: DecisionTreeRegressor, MSE = 0.0862\n",
      "Base Estimator: KNeighborsRegressor, MSE = 0.0680\n"
     ]
    }
   ],
   "source": [
    "# 40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "for base in [DecisionTreeRegressor(), KNeighborsRegressor()]:\n",
    "    model = BaggingRegressor(estimator=base, n_estimators=20, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    print(f\"Base Estimator: {type(base).__name__}, MSE = {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e009be1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9606481481481481\n"
     ]
    }
   ],
   "source": [
    "# 41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf61610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.925 0.865 0.905 0.88  0.875]\n",
      "Mean Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# 42. Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "bag = BaggingClassifier(n_estimators=50, random_state=1)\n",
    "scores = cross_val_score(bag, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bdb9731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x2d8f2482660>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 43. Train a Random Forest Classifier and plot the Precision-Recall curve.\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac175008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking (RF + LogReg) Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# 44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=50)),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stack.fit(X_train, y_train)\n",
    "print(\"Stacking (RF + LogReg) Accuracy:\", stack.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f7af617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample = 0.5, MSE = 0.0876\n",
      "Bootstrap Sample = 0.7, MSE = 0.0877\n",
      "Bootstrap Sample = 1.0, MSE = 0.0837\n"
     ]
    }
   ],
   "source": [
    "# 45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
    "for max_samples in [0.5, 0.7, 1.0]:\n",
    "    model = BaggingRegressor(n_estimators=30, max_samples=max_samples, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    print(f\"Bootstrap Sample = {max_samples}, MSE = {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e43b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
